{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> **Assignment 6: Object detection using Transfer Learning of CNN architectures**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install seaborn (plotting library). In notebooks, !pip or %pip is preferred.\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in d:\\my\\4th year\\3 deep learning\\lab\\venv\\lib\\site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install torchsummary to print a layer-by-layer model summary\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries (PyTorch, data tools, plotting)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "# PyTorch\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "# Useful for examining network\n",
    "from torchsummary import summary\n",
    "# Timing utility\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Show outputs of all statements in a cell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on gpu: False\n"
     ]
    }
   ],
   "source": [
    "# Set paths to training/validation/test folders and basic settings\n",
    "# Note: edit 'datadir' below to match your data location\n",
    "# Location of data\n",
    "datadir = '/home/wjk68/'\n",
    "traindir = datadir + 'train/'\n",
    "validdir = datadir + 'valid/'\n",
    "testdir = datadir + 'test/'\n",
    "\n",
    "save_file_name = 'vgg16-transfer-4.pt'\n",
    "checkpoint_path = 'vgg16-transfer-4.pth'\n",
    "\n",
    "# Adjust batch size based on your GPU/CPU memory\n",
    "batch_size = 128\n",
    "\n",
    "# Check if a CUDA GPU is available\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Detect number of GPUs (for optional multi-GPU training)\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/home/wjk68/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m ws = []\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Iterate through each category\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     14\u001b[39m     categories.append(d)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Number of each image\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/home/wjk68/train/'"
     ]
    }
   ],
   "source": [
    "# Scan dataset folders to count images per category and record image sizes\n",
    "# Empty lists\n",
    "categories = []\n",
    "img_categories = []\n",
    "n_train = []\n",
    "n_valid = []\n",
    "n_test = []\n",
    "hs = []\n",
    "ws = []\n",
    "\n",
    "# Iterate through each category\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "    # Number of images in each split\n",
    "    train_imgs = os.listdir(traindir + d)\n",
    "    valid_imgs = os.listdir(validdir + d)\n",
    "    test_imgs = os.listdir(testdir + d)\n",
    "    n_train.append(len(train_imgs))\n",
    "    n_valid.append(len(valid_imgs))\n",
    "    n_test.append(len(test_imgs))\n",
    "\n",
    "    # Collect height/width for train images\n",
    "    for i in train_imgs:\n",
    "        img_categories.append(d)\n",
    "        img = Image.open(traindir + d + '/' + i)\n",
    "        img_array = np.array(img)\n",
    "        # Shape\n",
    "        hs.append(img_array.shape[0])\n",
    "        ws.append(img_array.shape[1])\n",
    "\n",
    "# Dataframe of categories\n",
    "cat_df = pd.DataFrame({'category': categories,\n",
    "                       'n_train': n_train,\n",
    "                       'n_valid': n_valid, 'n_test': n_test}).\\\n",
    "    sort_values('category')\n",
    "\n",
    "# Dataframe of training images\n",
    "image_df = pd.DataFrame({\n",
    "    'category': img_categories,\n",
    "    'height': hs,\n",
    "    'width': ws\n",
    "})\n",
    "\n",
    "# Sort by most training images\n",
    "cat_df.sort_values('n_train', ascending=False, inplace=True)\n",
    "cat_df.head()\n",
    "cat_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of training images per category\n",
    "cat_df.set_index('category')['n_train'].plot.bar(\n",
    "    color='r', figsize=(20, 6))\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Images by Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 50 categories by training image count (if dataset is large)\n",
    "cat_df.set_index('category').iloc[:50]['n_train'].plot.bar(\n",
    "    color='r', figsize=(20, 6))\n",
    "plt.xticks(rotation=80)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Training Images by Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe training image sizes per category (min/mean/max, etc.)\n",
    "img_dsc = image_df.groupby('category').describe()\n",
    "img_dsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of average image height and width across categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    img_dsc['height']['mean'], label='Average Height')\n",
    "sns.kdeplot(\n",
    "    img_dsc['width']['mean'], label='Average Width')\n",
    "plt.xlabel('Pixels')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Average Size Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Pretrained ImageNet models expect 224x224 RGB images\n",
    "# Larger images will be center-cropped; smaller images are resized/interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to display a PIL image with no axes\n",
    "def imshow(image):\n",
    "    \"\"\"Display image\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example image: open from a category folder and show\n",
    "x = Image.open(traindir + 'ewer/image_0002.jpg')\n",
    "np.array(x).shape\n",
    "imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Image transformations (train gets random augmentations; val/test are deterministic)\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # ImageNet standard size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # ImageNet means/stds\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a normalized tensor as an image (undo normalization for display)\n",
    "def imshow_tensor(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Set the color channel as the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Reverse the preprocessing steps\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Clip the image pixel values\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    return ax, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one example raw image\n",
    "ex_img = Image.open('/home/wjk68/train/elephant/image_0024.jpg')\n",
    "imshow(ex_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = image_transforms['train']\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    _ = imshow_tensor(t(ex_img), ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using dataloaders for speedy iterations\n",
    "'''This construction avoids the need to load all the data into memory and also will automatically apply the transformations to each batch. On each epoch, the Random transformations will be different so the network will essentially see multiple versions of each training image.'''\n",
    "\n",
    "# Datasets from each folder\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'val':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['val']),\n",
    "    'test':\n",
    "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Dataloader iterators\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(cat_df)\n",
    "print(f'There are {n_classes} different classes.')\n",
    "\n",
    "len(data['train'].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the pre-trained model -vgg for first few convolutional trained layers\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual training to be done only on classifier layer. rest as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze early layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train a classifier consisting of the following layers\n",
    "\n",
    "Fully connected with ReLU activation (n_inputs, 256)\n",
    "Dropout with 40% chance of dropping\n",
    "Fully connected with log softmax output (256, n_classes)'''\n",
    "\n",
    "n_inputs = model.classifier[6].in_features\n",
    "\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.4),\n",
    "    nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving to gpu\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load in pretrained model\n",
    "def get_pretrained_model(model_name):\n",
    "    \"\"\"Retrieve a pre-trained model from torchvision\n",
    "\n",
    "    Params\n",
    "    -------\n",
    "        model_name (str): name of the model (currently only accepts vgg16 and resnet50)\n",
    "\n",
    "    Return\n",
    "    --------\n",
    "        model (PyTorch model): cnn\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Freeze early layers\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        n_inputs = model.classifier[6].in_features\n",
    "\n",
    "        # Add on classifier\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        n_inputs = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # Move to gpu and parallelize\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pretrained_model('vgg16')\n",
    "if multi_gpu:\n",
    "    summary(\n",
    "        model.module,\n",
    "        input_size=(3, 224, 224),\n",
    "        batch_size=batch_size,\n",
    "        device='cuda')\n",
    "else:\n",
    "    summary(\n",
    "        model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_gpu:\n",
    "    print(model.module.classifier[6])\n",
    "else:\n",
    "    print(model.classifier[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping of classes to indexes\n",
    "\n",
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() #keeps track of the loss itself and the gradients of the loss with respect to the model parameters (weights)\n",
    "optimizer = optim.Adam(model.parameters()) #updates the parameters (weights) with the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=2):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=5,\n",
    "    n_epochs=30,\n",
    "    print_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training results shown graphically\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(\n",
    "        history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'valid_acc']:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy cones out to be >80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function processes an image path into a PyTorch tensor for predictions. It applies the same transformations as was done to the validation data: cropping (center) and normalizing with means and standard deviations.'''\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    # Resize\n",
    "    img = image.resize((256, 256))\n",
    "\n",
    "    # Center crop\n",
    "    width = 256\n",
    "    height = 256\n",
    "    new_width = 224\n",
    "    new_height = 224\n",
    "\n",
    "    left = (width - new_width) / 2\n",
    "    top = (height - new_height) / 2\n",
    "    right = (width + new_width) / 2\n",
    "    bottom = (height + new_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert to numpy, transpose color dimension and normalize\n",
    "    img = np.array(img).transpose((2, 0, 1)) / 256\n",
    "\n",
    "    # Standardization\n",
    "    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "    img = img - means\n",
    "    img = img / stds\n",
    "\n",
    "    img_tensor = torch.Tensor(img)\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = process_image(testdir + 'dragonfly/image_0015.jpg')\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, image = imshow_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, image = imshow_tensor(process_image(testdir + 'dalmatian/image_0053.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fucntion to make predictions\n",
    "\n",
    "def predict(image_path, model, topk=5):\n",
    "    \"\"\"Make a prediction for an image using a trained model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        image_path (str): filename of the image\n",
    "        model (PyTorch model): trained model for inference\n",
    "        topk (int): number of top predictions to return\n",
    "\n",
    "    Returns\n",
    "\n",
    "    \"\"\"\n",
    "    real_class = image_path.split('/')[-2]\n",
    "\n",
    "    # Convert to pytorch tensor\n",
    "    img_tensor = process_image(image_path)\n",
    "\n",
    "    # Resize\n",
    "    if train_on_gpu:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224)\n",
    "\n",
    "    # Set to evaluation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(img_tensor)\n",
    "        ps = torch.exp(out)\n",
    "\n",
    "        # Find the topk predictions\n",
    "        topk, topclass = ps.topk(topk, dim=1)\n",
    "\n",
    "        # Extract the actual classes and probabilities\n",
    "        top_classes = [\n",
    "            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n",
    "        ]\n",
    "        top_p = topk.cpu().numpy()[0]\n",
    "\n",
    "        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 100\n",
    "\n",
    "\n",
    "def random_test_image():\n",
    "    \"\"\"Pick a random test image from the test directory\"\"\"\n",
    "    c = np.random.choice(cat_df['category'])\n",
    "    root = testdir + c + '/'\n",
    "    img_path = root + np.random.choice(os.listdir(root))\n",
    "    return img_path\n",
    "\n",
    "\n",
    "_ = imshow_tensor(process_image(random_test_image()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, top_p, top_classes, real_class = predict(random_test_image(), model)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, top_p, top_classes, real_class = predict(random_test_image(), model)\n",
    "top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display predictions. some predicted classes are shown but title seems to be the true class\n",
    "\n",
    "def display_prediction(image_path, model, topk):\n",
    "    \"\"\"Display image and preditions from model\"\"\"\n",
    "\n",
    "    # Get predictions\n",
    "    img, ps, classes, y_obs = predict(image_path, model, topk)\n",
    "    # Convert results to dataframe for plotting\n",
    "    result = pd.DataFrame({'p': ps}, index=classes)\n",
    "\n",
    "    # Show the image\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax, img = imshow_tensor(img, ax=ax)\n",
    "\n",
    "    # Set title to be the actual class\n",
    "    ax.set_title(y_obs, size=20)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    # Plot a bar plot of predictions\n",
    "    result.sort_values('p')['p'].plot.barh(color='blue', edgecolor='k', ax=ax)\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(random_test_image(), model, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(random_test_image(), model, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the accuracy\n",
    "def accuracy(output, target, topk=(1, )):\n",
    "    \"\"\"Compute the topk accuracy(s)\"\"\"\n",
    "    if train_on_gpu:\n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # Find the predicted classes and transpose\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        # Determine predictions equal to the targets\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "\n",
    "        # For each k, find the percentage of correct\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(dataloaders['test'])\n",
    "# Get a batch of testing images and labels\n",
    "features, targets = next(testiter)\n",
    "\n",
    "if train_on_gpu:\n",
    "    accuracy(model(features.to('cuda')), targets, topk=(1, 5))\n",
    "else:\n",
    "    accuracy(model(features), targets, topk=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising results\n",
    "\n",
    "results = results.merge(cat_df, left_on='class', right_on='category').\\\n",
    "    drop(columns=['category'])\n",
    "\n",
    "# Plot using seaborn\n",
    "sns.lmplot(\n",
    "    y='top1', x='n_train', data=results, height=6)\n",
    "plt.xlabel('images')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Top 1 Accuracy vs Number of Training Images')\n",
    "plt.ylim(-5, 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Category with minimum accuracy.')\n",
    "results.loc[results['top1'].idxmin]\n",
    "\n",
    "print('Category with minimum images.')\n",
    "results.loc[results['n_train'].idxmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    y='top5', x='n_train', data=results, height=6)\n",
    "plt.xlabel('images')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Top 5 Accuracy vs Number of Training Images')\n",
    "plt.ylim(-5, 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted column of test images\n",
    "results['weighted'] = results['n_test'] / results['n_test'].sum()\n",
    "\n",
    "# Create weighted accuracies\n",
    "for i in (1, 5):\n",
    "    results[f'weighted_top{i}'] = results['weighted'] * results[f'top{i}']\n",
    "\n",
    "# Find final accuracy accounting for frequencies\n",
    "top1_weighted = results['weighted_top1'].sum()\n",
    "top5_weighted = results['weighted_top5'].sum()\n",
    "loss_weighted = (results['weighted'] * results['loss']).sum()\n",
    "\n",
    "print(f'Final test cross entropy per image = {loss_weighted:.4f}.')\n",
    "print(f'Final test top 1 weighted accuracy = {top1_weighted:.2f}%')\n",
    "print(f'Final test top 5 weighted accuracy = {top5_weighted:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fucntion to display the predictions for an image\n",
    "\n",
    "def display_category(model, category, n=4):\n",
    "    \"\"\"Display predictions for a category    \n",
    "    \"\"\"\n",
    "    category_results = results.loc[results['class'] == category]\n",
    "    print(category_results.iloc[:, :6], '/n')\n",
    "\n",
    "    images = np.random.choice(\n",
    "        os.listdir(testdir + category + '/'), size=4, replace=False)\n",
    "\n",
    "    for img in images:\n",
    "        display_prediction(testdir + category + '/' + img, model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_category(model, 'mandolin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
